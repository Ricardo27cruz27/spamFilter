\documentclass[12pt, letterpaper]{article}
\usepackage[colorlinks=true,linkcolor=black,citecolor=blue,filecolor=cyan,pagecolor=blue]{hyperref} 
\usepackage[toc,style=altlistgroup,hyperfirst=false]{glossaries}
\usepackage[utf8]{inputenc} %para poder escribir símbolos no anglosajones 
\usepackage[spanish, mexico]{babel} %Escribir en español (acentos)
\usepackage[T1]{fontenc}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage[usenames]{color}
\usepackage{float}
\usepackage{graphicx}  %%para las imagenes
\usepackage{cite} % para contraer referencias
\usepackage{multicol}
\usepackage{multirow}
\usepackage{bm}
\usepackage{subfig}
\usepackage{bbm}
\usepackage[left=2.5cm,top=2.5cm,right=2.5cm,bottom=2.5cm]{geometry}
\parindent=5mm
\graphicspath{{images/}}
\usepackage{etoolbox}
\let\bbordermatrix\bordermatrix
%\patchcmd{\bbordermatrix}{8.75}{4.75}{}{}
%\patchcmd{\bbordermatrix}{\left(}{\left[}{}{}
%\patchcmd{\bbordermatrix}{\right)}{\right]}{}{}
%%%%glosario
\makeindex
%\makeglossaries
%\input{./glosario.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%NOTA IMPORTANTE:
%%Para relacionar el glosario.tex con este archivo
%%Es necesario abrir la terminal (Simbolo del sistema en windows)
%%Ir a la carpeta contenedora y escribir el siguiente comando:
%%makeindex -s PROYECTO_final.ist -t PROYECTO_final.glg -o PROYECTO_final.gls PROYECTO_final.glo
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%% inicio del documento
\begin{document}

\thispagestyle{empty}

%%%%%%% portada

\thispagestyle{empty}

\begin{minipage}[c][0.1\textheight][c]{0.2\textwidth}
\begin{center}
    \includegraphics[width=4cm, height=4cm]{cimat}
\end{center}
\end{minipage}
\begin{minipage}[c][0.1\textheight][t]{0.8\textwidth}
\begin{center}
    {\hspace{2cm}\scshape Centro de Investigación en Matemáticas}
    \vspace{-.5cm}
\end{center}
\hspace*{1.0cm} \rule[0mm]{0.9\textwidth}{0.8mm}
\hspace*{1.17cm}   \rule[4mm]{0.9\textwidth}{0.1mm}
    \vspace{-1cm}
\begin{center}
    { \hspace{2cm}\scshape  Unidad Monterrey}
\end{center}
\end{minipage}

\begin{minipage}[c][0.6\textheight][t]{0.2\textwidth}
\begin{center}
\hskip2pt
\vrule width2.5pt height10cm
        \hskip1mm
        \vrule width1pt height10cm \\ \vspace{2cm}
        \includegraphics[height=4.5cm]{mty}
        \end{center}
\end{minipage}
\begin{minipage}[c][0.9\textheight][t]{0.65\textwidth}
  \begin{center}

	
    \vspace{3.2cm}
    
%%%% TITULO EN PORTADA

  \scshape Proyecto No. 1.\\ \normalsize
  
  \vspace{2cm}  
  
    
            
    Métodos multivariados de Análisis de Datos\\
    \vspace{1cm}   
    Filtro de spam personalizado.\\
    \vspace{1cm}   
    \vspace{1cm}   
    Ricardo Cruz Sánchez\\
    Rolando Corona Jiménez
    \vspace{.5cm}   
  \end{center}
  
\end{minipage}

%TABLA DE INDICES
\pagebreak
\tableofcontents

\cleardoublepage
%INTRODUCCIÓN
\pagebreak
\section{Introducción.}

Aplicación de modelos de clasificación para obtener un filtro (personalizado) para correos electrónicos spam.

\section{Análisis exploratorio.}

\subsection{Descripción del conjunto de datos.}

El conjunto de datos proviene de una serie de correos electrónicos del personal de la empresa HP. Los correos etiquetados como spam fueron proporcionados por el administrador del servidor de correo de la empresa, mientras que los correos que no están etiquetados como spam corresponden a correos personales y de trabajo de George Forman, es por ello que palabras como \textit{george} o código de área $650$ son indicadores de no spam. La base de datos fue creada por Mark Hopkins, Erik Reeber, George Forman y Jaap Suermondt de Hewlett-Packard Labs.

En total se cuentan 4601 observaciones, de las cuales 1813 fueron etiquetadas como spam, que corresponde al $39.4\%$ del total. Las observaciones están representadas a través de un conjunto de 58 atributos: $57$ variables cuantitativas y una variable cualitativa nominal de clase. Ninguno de los atributos presenta datos faltantes. 

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|}
\hline
Spam     & $1813$ & $39.4 \%$ \\ \hline
Non-Spam & $2788$ & $60.6 \%$ \\ \hline
\end{tabular}
\caption{Distribución de clases.}
\label{t_dist}
\end{table}

\subsection{Diccionario de datos}

Los 58 atributos se pueden agrupar en:

\begin{itemize}
	\item 48 variables cuantitativas continuas con rango $[0,100]$, de la forma word\_freq\_WORD, que indica el porcentaje de palabras en el correo que coinciden con WORD, es decir:
	$$word\_freq\_WORD = 100 \times \dfrac{\#\text{apariciones de WORD en el correo}}{\#\text{total de palabras en el correo}}$$
	
	\item 6 variables cuantitativas continuas con rango $[0,100]$, de la forma char\_freq\_CHAR, que indica el porcentaje de caracteres en el correo que coinciden con CHAR, es decir:	
		$$char\_freq\_CHAR = 100 \times \dfrac{\#\text{apariciones de CHAR en el correo}}{\#\text{total de caracteres en el correo}}$$
		
	\item 1 variable cuantitativa continua \textsf{capital\_run\_length\_average} con rango $[0,\infty)$, que es igual a longitud media de las secuencias contiguas de letras mayúsculas que aparecen en el correo.
	
	\item 1 variable cuantitativa discreta \textsf{capital\_run\_length\_longest} con rango $[0,\infty)$, que es igual a la longitud de la secuencia contigua de letras mayúsculas más larga que aparece en el correo.
	
	\item 1 variable cuantitativa discreta \textsf{capital\_run\_length\_total} con rango $[0,\infty)$, que es igual a la suma de las longitudes de las secuencias contiguas de letras mayúsculas que aparecen en el correo.
	
	\item 1 variable nominal de clase con valores en $\{0, 1\}$, que indica si el correo se considera spam (1) o no (0).
\end{itemize}

La documentación del conjunto de datos no indica los criterios para la selección de las 48 palabras y 6 caracteres usados para la definición de sus correspondientes variables.

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
make     & order     & business & hp     & data       & cs         \\ \hline
address  & mail      & email    & hpl    & 415        & meeting    \\ \hline
all      & receive   & you      & george & 85         & original   \\ \hline
3d       & will      & credit   & 650    & technology & project    \\ \hline
our      & people    & your     & lab    & 1999       & re         \\ \hline
over     & report    & font     & labs   & parts      & edu        \\ \hline
remove   & addresses & 000      & telnet & pm         & table      \\ \hline
internet & free      & money    & 857    & direct     & conference \\ \hline
\end{tabular}
\caption{Palabras que corresponden a las variables de tipo word\_freq\_WORD.}
\label{t_words}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|}
\hline
;   \\ \hline
(   \\ \hline
{[} \\ \hline
!   \\ \hline
\$  \\ \hline
\#  \\ \hline
\end{tabular}
\caption{Caracteres que corresponden a las variables de tipo char\_freq\_CHAR.}
\label{t_chars}
\end{table}

\subsection{Matriz de correlación.}

\subsection{Palabras más frecuentes por clase.}

A modo de resumen se muestra una representación gráfica de las palabras más frecuentes por cada clase, para obtener la frecuencia de cada palabra, se realizó la suma de cada variable sobre todas las observaciones de cada clase.

\section{Métricas para clasificación binaria.}

Las métricas de evaluación permiten medir y resumir la calidad de un modelo entrenado al ser probado con nuevas observaciones. La exactitud ($accuracy$) es una de las métricas más comunes para evaluar la capacidad de generalización de un clasificador, sin embargo no siempre resulta ser la ideal, y esto depende específicamente del problema en cuestión. Entre la distintas métricas que existen para el problema de clasificación binaria, a continuación se mencionan algunas, para finalmente discutir sobre cuál es la ideal para la clasificación de spam, con el fin de tener un criterio de preferencia entre los clasificadores que serán presentados más adelante. \\

Existen dos tipos de errores al asignar una clase a una observación: el \textit{falso positivo} $fp$ (diagnóstico positivo, condición de interés ausente) y el \textit{falso negativo} $fn$(diagnóstico negativo, condición de interés presente). De forma similar se definen los verdaderos positivos $tp$ y verdaderos negativos $tn$. \\

A partir de lo anterior, se definen las métricas de interés que se muestran en la tabla \ref{t_metricas}.

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Métrica} & \textbf{Fórmula}             & \textbf{Enfoque de la evaluación}                \\ \hline
Accuracy         & $\dfrac{tp+tn}{tp+fn+fp+tn}$ & Desempeño general                                \\ \hline
Sensitivity      & $\dfrac{tp}{tp+fn}$          & Efectividad para identificar a la clase positiva \\ \hline
Specificity      & $\dfrac{tn}{fp+tn}$          & Efectividad para identificar a la clase negativa \\ \hline
\end{tabular}
\caption{Métricas para clasificación binaria}
\label{t_metricas}
\end{table}

\subsection{Selección de métricas para el problema del spam.}

Para la clasificación de spam, es fundamental que los correos que no son spam, en la medida de lo posible, no sea etiquetados como spam, pues de lo contrario, los usuarios podrían perder información de valor si no revisan periódicamente la bandeja de spam, lo cual sería contraproducente. Dicho en términos de las métricas mencionadas anteriormente, se desea un clasificador con alta especificidad (specificity), de modo que la probabilidad de que un correo que no es spam no sea marcado como spam, sea alta. Sin embargo, puede pasar que al aumentar la especificidad, la exactitud y la sensibilidad (sensitivity) se vean reducidas, lo que causaría que el clasificador no se capaz de identificar muchos correos que deberían ser marcados como spam, en cuyo caso el usuario los recibiría en su bandeja principal y tendría que marcar manualmente dichos correos como spam. Este último enfoque es preferido, pues se trata de garantizar que los usuarios no pierdan información de valor. Teniendo en cuenta estas consideraciones, se procede a ajustar una serie de clasificadores binarios.


\section{Modelos de clasificación.}

Los modelos a continuación presentados, se implementaron a través del paquete estadístico $R$. Para su análisis se requiere la separación del conjunto original de datos en un conjunto de entrenamiento (aquél con el que se ajustan los modelos) y un conjunto de prueba (conjunto con el que se validan los resultados).\\

En este caso, se optó por un muestreo aleatorio para generar ambas submuestras. El conjunto de entrenamiento consiste de 3680 observaciones (aproximadamente un $80\%$) y el de prueba contiene 921 observaciones.

\subsection{Regresión logística.}
La regresión logística, es un caso particular de los modelos lineales generalizados. Su característica principal es el tener una variable dependiente dicotómica. Utilizá la función enlace \emph{logit} y gracias a esto se modela:

$$logit(p)=ln(\dfrac{p}{1-p})=\beta x$$

donde $p$ corresponde a la probabilidad asociada a la distribución binomial de la cual se generan los valores de $y$, es decir, $y\thicksim Bin(n,p)$\\

Una vez que se encuentran los parámetros $\beta$, solo es cuestión de evaluar la observación de las variables independientes $x$ y obtener el valor de $p$ aplicando la función inversa de \emph{logit}.\\

El valor estimado de $y$ dependerá de $p$ y un \emph{punto de corte}, que usualmente es el valor $0.5$, ya que si la observación es más grande que el punto de corte quiere decir que $y$ se asemeja más a la distribución de los valores $y=1$ y se asignará como 1. En caso de ser menor al punto de corte se determina que el valor estimado es 0.\\

Se ajustó la regresión considerando las 57 variables, lo cual arrojo las métricas mostradas en la tabla \ref{log1}:

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|}
\hline
&Entrenamiento&Prueba\\
\hline\hline
Accuracy& $.93$ & $.92 \%$ \\ \hline
Recall & $.90$ & $.88 \%$ \\ \hline
Specificity & $.92$ & $.94 \%$ \\ \hline
\end{tabular}
\caption{Métricas modelo full.}
\label{log1}
\end{table}

Regresando al punto de corte, se esperaría que las distribuciones de los casos verdaderos positivos y verdaderos negativos, tenga un comportamiento similar al de la figura \ref{cutoff}, tratando de minimizar las áreas de falsos positivos y negativos.

\begin{figure}
\centering
\includegraphics[scale=.75]{images/punto_de_corte.png} 
\caption{Distribuciones de TP y FP con relación al punto de corte.}
\label{cutoff}
\end{figure}

Se puede cambiar el punto de corte para tratar de minimizar las áreas de errores y por ende mejorar las métricas mencionadas. Cabe resaltar que el punto de corte se determina con el conjunto de entrenamiento.\\

La figura \ref{log2} muestra las distribuciones de verdaderos positivos y negativos para el conjunto de entrenamiento. En las distribuciones de entrenamiento se muestra como se puede desplazar el punto de corte a la izquierda para poder minimizar las áreas de falsos.

\begin{figure}[h]
 \centering
  \subfloat[Entrenamiento]{
    \includegraphics[width=0.5\textwidth]{images/dist1.png}}
  \subfloat[Prueba]{
    \includegraphics[width=0.5\textwidth]{images/dist2.png}}
 \caption{Densidades TP y TN}
 \label{log2}
\end{figure}

Por lo anterior, se plantea recorrer el punto de corte, a donde se intersectan las dos distribuciones ($0.4227$). El resultado de esto se muestra en la figura \ref{log4} y la tabla \ref{log3}

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|}
\hline
&Entrenamiento&Prueba\\
\hline\hline
Accuracy& $.93\%$ & $.91 \%$ \\ \hline
Recall & $.91\%$ & $.90 \%$ \\ \hline
Specificity & $.95\%$ & $.93 \%$ \\ \hline
\end{tabular}
\caption{Métricas modelo full, punto de corte 0.42}
\label{log3}
\end{table}


\begin{figure}[h]
 \centering
  \subfloat[Entrenamiento]{
    \includegraphics[width=0.5\textwidth]{images/dist3.png}}
  \subfloat[Prueba]{
    \includegraphics[width=0.5\textwidth]{images/dist4.png}}
 \caption{Densidades TP y TN}
 \label{log4}
\end{figure}

Se puede apreciar que las métricas no se modificaron significativamente, por lo que se podría dejar el punto de corte donde inicialmente estaba. Esto depende totalmente de la estrategia que se quiera seguir y se debe estar consciente que las medidas de sensitivity y specificity son complementarias, es decir, existe un \emph{trade-off} entre estas dos medidas al cambiar el punto de corte.\\

Por ejemplo, si la estrategia a seguir fuese no dejar pasar como spam a ningún correo que realmente no sea spam, entonces el punto de corte debe despalzarse hasta la probabilidad máxima observada en los verdaderos negativos durante el entrenamiento. La tabla \ref{log5} muestra los resultados de plantear esta estratégia:

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|}
\hline
&Entrenamiento&Prueba\\
\hline\hline
Accuracy& $.63\%$ & $.63 \%$ \\ \hline
Recall & $.08\%$ & $.09 \%$ \\ \hline
Specificity & $1\%$ & $1 \%$ \\ \hline
\end{tabular}
\caption{Métricas modelo full, punto de corte 0.9945}
\label{log5}
\end{table}


En las densidades mostradas se puede observar que las distribuciones se concentran demasiado en los extremos, es decir, las probabilidades generadas están muy cerca de 0 y 1. De hecho, esto aparece como un \emph{warning} al generar los modelos, en consola se puede leer que se generaron probabilidades 0 ó 1.\\

Este comportamiento se conoce como \emph{separación completa o quasi completa} y se genera cuando para una categoría en particular, se puede observar el valor constante de alguna o algunas variables, lo cual llevaría a que se pueda determinar el valor de la respuesta con solo ver las variables que son constantes, es decir, sería un modelo determinista.\\

Esto puede generar sobreajuste o una mala definición del modelo para observaciones futuras. Sus posibles soluciones son considerar más observaciones en el conjunto original o realizar una selección de variables.\\

Se optará por la segunda alternativa. Al ejecutar un proceso de selección de variables a través de un método stepwise y AIC como criterio del modelo, se obtienen 41 variables.\\

Sin embargo, el desempeño es bastante similar y continua la separación completa. Así que, tal vez, no sea un problema de sobreajuste, sino la naturaleza misma del evento que se estudia. La tabla \ref{log6} contiene las métricas de este nuevo modelo y la figura \ref{log7} las respectivas densidades


\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|}
\hline
&Entrenamiento&Prueba\\
\hline\hline
Accuracy& $.93\%$ & $.92 \%$ \\ \hline
Recall & $.91\%$ & $.88 \%$ \\ \hline
Specificity & $.94\%$ & $.94 \%$ \\ \hline
\end{tabular}
\caption{Métricas modelo stepwisw}
\label{log6}
\end{table}


\begin{figure}[h]
 \centering
  \subfloat[Entrenamiento]{
    \includegraphics[width=0.5\textwidth]{images/dist5.png}}
  \subfloat[Prueba]{
    \includegraphics[width=0.5\textwidth]{images/dist6.png}}
 \caption{Densidades TP y TN}
 \label{log7}
\end{figure}

Finalmente, en este método, se consideraron los coeficientes más importantes de acuerdo a la magnitud que poseían:

\begin{itemize}
\item char$\_$freq$\_\$$: 6.66
\item cs: -508.4
\item george: -9.81
\item conference: -4.52
\item meeting: -2.69
\end{itemize} 

\subsection{Lasso y Ridge}

Una de las posibles alternativas son los métodos de regularización, los cuales pueden seleccionar variables y mejorar las estimaciones de los coeficientes haciendolos tender a 0.\\

Para implementar estos dos métodos, primero se realiza validación cruzada, con lo que se determinará el valor de $\lambda$ en cada caso. \\

C-V sugiere utilizar $\lambda=.018$ para ridge y $\lambda=0.00049$ para lasso. Con estos dos valores lasso selecciona 54 variables, mientras que ridge ocupa todas aunque las aproxima a 0.\\

La tabla \ref{lasso} muestra el desempeño de ambos modelos en el conjunto de prueba:

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|}
\hline
&Lasso&Ridge\\
\hline\hline
Accuracy& $.90\%$ & $.87 \%$ \\ \hline
Recall & $.82\%$ & $.73 \%$ \\ \hline
Specificity & $.96\%$ & $.96 \%$ \\ \hline
\end{tabular}
\caption{Métricas modelo lasso y ridge}
\label{lasso}
\end{table}

No se mejoró el desempeño de la regresión original, de hecho, la logisitic full, sigue siendo la mejor de los modelos hasta ahora presentados.
\subsection{Máquinas de soporte vectorial.}

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|}
\hline
&SVM&Bayes\\
\hline\hline
Accuracy& $.91\%$ & $.91 \%$ \\ \hline
Recall & $.88\%$ & $.91 \%$ \\ \hline
Specificity & $.93\%$ & $.92 \%$ \\ \hline
\end{tabular}
\caption{Métricas svm y regresion bayesiana}
\label{svm}
\end{table}



\subsection{Árboles de decisión.}

El índice de Gini se define como 

$$ G $$ 

gini
podado
matriz de costo

%o bagging
\subsection{Random Forest.}

\subsection{Modelos con reducción de dimensión y selección de variables}

\subsection{Representación en componentes principales.}

Se calculan las componentes principales y se grafica el screeplot, que muestra el porcentaje de varianza acumulada en función del número de componentes principales. La figura \ref{screeplot} muestra que, por ejemplo para explicar el $80\%$ de varianza, se requieren de al menos $30$ componentes principales, 
lo que sugiere que los modelos entrenados en dimensión reducida pueden tener un ajuste deficiente.

\begin{figure}[h]
\centering
	\includegraphics[scale=.5]{images/pca.png} 
	\caption{Screeplot}
		\label{screeplot}
\end{figure}


\subsection{Comparativa con otros modelos}

%provenientes de articulos
de spambase.DOCUMENTATION
$~7\%$ misclassification error.
False positives (marking good mail as spam) are very undesirable.
If we insist on zero false positives in the training/testing set,
$20-25\%$ of the spam passed through the filter.

revisar papers donde trabajan con el ejemplo

\section{Conclusiones.}
Yo digo que no hay pedo

\begin{thebibliography}{1}

\bibitem{cr98}
Lorrie Faith Cranor and Brian A. LaMacchia. 1998. Spam!. Commun. ACM 41, 8 (August 1998), 74-83. 

\bibitem{fe19}
Emilio Ferrara. 2019. The history of digital spam. Commun. ACM 62, 8 (July 2019), 82-91. 

\bibitem{ha01}
Hastie, T., Tibshirani, R.,, Friedman, J. (2001). The Elements of Statistical Learning. New York, NY, USA: Springer New York Inc.. 

\bibitem{so09}
Marina Sokolova and Guy Lapalme. 2009. A systematic analysis of performance measures for classification tasks. Inf. Process. Manage. 45, 4 (July 2009), 427-437. 

\end{thebibliography}

\end{document}